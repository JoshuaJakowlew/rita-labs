2023-03-02 20:28:31,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-02 20:28:31,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-02 20:28:31,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-02 20:28:31,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-02 20:28:31,534:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-02 20:29:32,140:INFO:PyCaret ClassificationExperiment
2023-03-02 20:29:32,140:INFO:Logging name: clf-default-name
2023-03-02 20:29:32,140:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-02 20:29:32,140:INFO:version 3.0.0.rc9
2023-03-02 20:29:32,140:INFO:Initializing setup()
2023-03-02 20:29:32,140:INFO:self.USI: 8662
2023-03-02 20:29:32,140:INFO:self._variable_keys: {'target_param', 'X_train', 'memory', 'seed', 'gpu_param', 'gpu_n_jobs_param', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'USI', 'pipeline', 'exp_name_log', 'y_train', 'idx', 'html_param', 'exp_id', 'fold_generator', 'X', 'data', 'y_test', 'is_multiclass', 'fix_imbalance', 'n_jobs_param', 'y', 'X_test', 'fold_groups_param', '_available_plots', 'log_plots_param'}
2023-03-02 20:29:32,140:INFO:Checking environment
2023-03-02 20:29:32,140:INFO:python_version: 3.10.9
2023-03-02 20:29:32,141:INFO:python_build: ('main', 'Dec 19 2022 17:35:49')
2023-03-02 20:29:32,141:INFO:machine: x86_64
2023-03-02 20:29:32,141:INFO:platform: Linux-6.2.1-arch1-1-x86_64-with-glibc2.37
2023-03-02 20:29:32,141:INFO:Memory: svmem(total=16695431168, available=7885381632, percent=52.8, used=8146182144, free=2809999360, active=7712296960, inactive=5065383936, buffers=544788480, cached=5194461184, shared=324608000, slab=575094784)
2023-03-02 20:29:32,142:INFO:Physical Core: 8
2023-03-02 20:29:32,142:INFO:Logical Core: 16
2023-03-02 20:29:32,142:INFO:Checking libraries
2023-03-02 20:29:32,142:INFO:System:
2023-03-02 20:29:32,142:INFO:    python: 3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]
2023-03-02 20:29:32,142:INFO:executable: /bin/python
2023-03-02 20:29:32,142:INFO:   machine: Linux-6.2.1-arch1-1-x86_64-with-glibc2.37
2023-03-02 20:29:32,142:INFO:PyCaret required dependencies:
2023-03-02 20:29:32,142:INFO:                 pip: 23.0.1
2023-03-02 20:29:32,142:INFO:          setuptools: 67.4.0
2023-03-02 20:29:32,142:INFO:             pycaret: 3.0.0rc9
2023-03-02 20:29:32,143:INFO:             IPython: 8.11.0
2023-03-02 20:29:32,143:INFO:          ipywidgets: 8.0.4
2023-03-02 20:29:32,143:INFO:                tqdm: 4.64.0
2023-03-02 20:29:32,143:INFO:               numpy: 1.24.2
2023-03-02 20:29:32,143:INFO:              pandas: 1.5.3
2023-03-02 20:29:32,143:INFO:              jinja2: 3.1.2
2023-03-02 20:29:32,143:INFO:               scipy: 1.10.1
2023-03-02 20:29:32,143:INFO:              joblib: 1.2.0
2023-03-02 20:29:32,143:INFO:             sklearn: 1.2.1
2023-03-02 20:29:32,143:INFO:                pyod: 1.0.7
2023-03-02 20:29:32,143:INFO:            imblearn: 0.10.1
2023-03-02 20:29:32,143:INFO:   category_encoders: 2.6.0
2023-03-02 20:29:32,143:INFO:            lightgbm: 3.3.5
2023-03-02 20:29:32,143:INFO:               numba: 0.56.4
2023-03-02 20:29:32,143:INFO:            requests: 2.28.2
2023-03-02 20:29:32,143:INFO:          matplotlib: 3.6.3
2023-03-02 20:29:32,143:INFO:          scikitplot: 0.3.7
2023-03-02 20:29:32,143:INFO:         yellowbrick: 1.5
2023-03-02 20:29:32,143:INFO:              plotly: 5.13.1
2023-03-02 20:29:32,143:INFO:             kaleido: 0.2.1
2023-03-02 20:29:32,143:INFO:         statsmodels: 0.13.5
2023-03-02 20:29:32,143:INFO:              sktime: 0.16.1
2023-03-02 20:29:32,143:INFO:               tbats: 1.1.2
2023-03-02 20:29:32,143:INFO:            pmdarima: 2.0.2
2023-03-02 20:29:32,143:INFO:              psutil: 5.9.1
2023-03-02 20:29:32,144:INFO:PyCaret optional dependencies:
2023-03-02 20:29:32,147:INFO:                shap: Not installed
2023-03-02 20:29:32,147:INFO:           interpret: Not installed
2023-03-02 20:29:32,147:INFO:                umap: Not installed
2023-03-02 20:29:32,147:INFO:    pandas_profiling: Not installed
2023-03-02 20:29:32,147:INFO:  explainerdashboard: Not installed
2023-03-02 20:29:32,147:INFO:             autoviz: Not installed
2023-03-02 20:29:32,147:INFO:           fairlearn: Not installed
2023-03-02 20:29:32,147:INFO:             xgboost: Not installed
2023-03-02 20:29:32,147:INFO:            catboost: Not installed
2023-03-02 20:29:32,147:INFO:              kmodes: Not installed
2023-03-02 20:29:32,147:INFO:             mlxtend: Not installed
2023-03-02 20:29:32,147:INFO:       statsforecast: Not installed
2023-03-02 20:29:32,147:INFO:        tune_sklearn: Not installed
2023-03-02 20:29:32,147:INFO:                 ray: Not installed
2023-03-02 20:29:32,147:INFO:            hyperopt: Not installed
2023-03-02 20:29:32,147:INFO:              optuna: Not installed
2023-03-02 20:29:32,147:INFO:               skopt: Not installed
2023-03-02 20:29:32,147:INFO:              mlflow: Not installed
2023-03-02 20:29:32,147:INFO:              gradio: Not installed
2023-03-02 20:29:32,147:INFO:             fastapi: Not installed
2023-03-02 20:29:32,147:INFO:             uvicorn: Not installed
2023-03-02 20:29:32,147:INFO:              m2cgen: Not installed
2023-03-02 20:29:32,147:INFO:           evidently: Not installed
2023-03-02 20:29:32,147:INFO:               fugue: Not installed
2023-03-02 20:29:32,147:INFO:           streamlit: Not installed
2023-03-02 20:29:32,147:INFO:             prophet: Not installed
2023-03-02 20:29:32,147:INFO:None
2023-03-02 20:29:32,147:INFO:Set up data.
2023-03-02 20:29:32,155:INFO:Set up train/test split.
2023-03-02 20:29:32,161:INFO:Set up index.
2023-03-02 20:29:32,162:INFO:Set up folding strategy.
2023-03-02 20:29:32,162:INFO:Assigning column types.
2023-03-02 20:29:32,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-02 20:29:32,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,214:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,302:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,332:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-02 20:29:32,380:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,459:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:32,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,489:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-02 20:29:32,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:32,646:INFO:Preparing preprocessing pipeline...
2023-03-02 20:29:32,648:INFO:Set up simple imputation.
2023-03-02 20:29:32,650:INFO:Set up encoding of ordinal features.
2023-03-02 20:29:32,651:INFO:Set up encoding of categorical features.
2023-03-02 20:29:32,707:INFO:Finished creating preprocessing pipeline.
2023-03-02 20:29:32,722:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-03-02 20:29:32,722:INFO:Creating final display dataframe.
2023-03-02 20:29:33,004:INFO:Setup _display_container:                     Description             Value
0                    Session id              8390
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7               Ignore features                 3
8              Ordinal features                 1
9              Numeric features                 6
10         Categorical features                 2
11     Rows with missing values             79.5%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              8662
2023-03-02 20:29:33,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:33,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:33,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:33,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:33,167:INFO:setup() successfully completed in 1.03s...............
2023-03-02 20:29:51,740:INFO:PyCaret ClassificationExperiment
2023-03-02 20:29:51,740:INFO:Logging name: clf-default-name
2023-03-02 20:29:51,741:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-03-02 20:29:51,741:INFO:version 3.0.0.rc9
2023-03-02 20:29:51,741:INFO:Initializing setup()
2023-03-02 20:29:51,741:INFO:self.USI: 73f3
2023-03-02 20:29:51,741:INFO:self._variable_keys: {'target_param', 'X_train', 'memory', 'seed', 'gpu_param', 'gpu_n_jobs_param', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'USI', 'pipeline', 'exp_name_log', 'y_train', 'idx', 'html_param', 'exp_id', 'fold_generator', 'X', 'data', 'y_test', 'is_multiclass', 'fix_imbalance', 'n_jobs_param', 'y', 'X_test', 'fold_groups_param', '_available_plots', 'log_plots_param'}
2023-03-02 20:29:51,741:INFO:Checking environment
2023-03-02 20:29:51,741:INFO:python_version: 3.10.9
2023-03-02 20:29:51,741:INFO:python_build: ('main', 'Dec 19 2022 17:35:49')
2023-03-02 20:29:51,741:INFO:machine: x86_64
2023-03-02 20:29:51,741:INFO:platform: Linux-6.2.1-arch1-1-x86_64-with-glibc2.37
2023-03-02 20:29:51,742:INFO:Memory: svmem(total=16695431168, available=7829401600, percent=53.1, used=8198320128, free=2753617920, active=7768698880, inactive=5069660160, buffers=545083392, cached=5198409728, shared=328466432, slab=575811584)
2023-03-02 20:29:51,742:INFO:Physical Core: 8
2023-03-02 20:29:51,743:INFO:Logical Core: 16
2023-03-02 20:29:51,743:INFO:Checking libraries
2023-03-02 20:29:51,743:INFO:System:
2023-03-02 20:29:51,743:INFO:    python: 3.10.9 (main, Dec 19 2022, 17:35:49) [GCC 12.2.0]
2023-03-02 20:29:51,743:INFO:executable: /bin/python
2023-03-02 20:29:51,743:INFO:   machine: Linux-6.2.1-arch1-1-x86_64-with-glibc2.37
2023-03-02 20:29:51,743:INFO:PyCaret required dependencies:
2023-03-02 20:29:51,743:INFO:                 pip: 23.0.1
2023-03-02 20:29:51,743:INFO:          setuptools: 67.4.0
2023-03-02 20:29:51,743:INFO:             pycaret: 3.0.0rc9
2023-03-02 20:29:51,743:INFO:             IPython: 8.11.0
2023-03-02 20:29:51,743:INFO:          ipywidgets: 8.0.4
2023-03-02 20:29:51,743:INFO:                tqdm: 4.64.0
2023-03-02 20:29:51,743:INFO:               numpy: 1.24.2
2023-03-02 20:29:51,743:INFO:              pandas: 1.5.3
2023-03-02 20:29:51,743:INFO:              jinja2: 3.1.2
2023-03-02 20:29:51,744:INFO:               scipy: 1.10.1
2023-03-02 20:29:51,744:INFO:              joblib: 1.2.0
2023-03-02 20:29:51,744:INFO:             sklearn: 1.2.1
2023-03-02 20:29:51,744:INFO:                pyod: 1.0.7
2023-03-02 20:29:51,744:INFO:            imblearn: 0.10.1
2023-03-02 20:29:51,744:INFO:   category_encoders: 2.6.0
2023-03-02 20:29:51,744:INFO:            lightgbm: 3.3.5
2023-03-02 20:29:51,744:INFO:               numba: 0.56.4
2023-03-02 20:29:51,744:INFO:            requests: 2.28.2
2023-03-02 20:29:51,744:INFO:          matplotlib: 3.6.3
2023-03-02 20:29:51,744:INFO:          scikitplot: 0.3.7
2023-03-02 20:29:51,744:INFO:         yellowbrick: 1.5
2023-03-02 20:29:51,744:INFO:              plotly: 5.13.1
2023-03-02 20:29:51,744:INFO:             kaleido: 0.2.1
2023-03-02 20:29:51,744:INFO:         statsmodels: 0.13.5
2023-03-02 20:29:51,744:INFO:              sktime: 0.16.1
2023-03-02 20:29:51,744:INFO:               tbats: 1.1.2
2023-03-02 20:29:51,744:INFO:            pmdarima: 2.0.2
2023-03-02 20:29:51,744:INFO:              psutil: 5.9.1
2023-03-02 20:29:51,744:INFO:PyCaret optional dependencies:
2023-03-02 20:29:51,745:INFO:                shap: Not installed
2023-03-02 20:29:51,745:INFO:           interpret: Not installed
2023-03-02 20:29:51,745:INFO:                umap: Not installed
2023-03-02 20:29:51,745:INFO:    pandas_profiling: Not installed
2023-03-02 20:29:51,745:INFO:  explainerdashboard: Not installed
2023-03-02 20:29:51,745:INFO:             autoviz: Not installed
2023-03-02 20:29:51,745:INFO:           fairlearn: Not installed
2023-03-02 20:29:51,745:INFO:             xgboost: Not installed
2023-03-02 20:29:51,745:INFO:            catboost: Not installed
2023-03-02 20:29:51,745:INFO:              kmodes: Not installed
2023-03-02 20:29:51,745:INFO:             mlxtend: Not installed
2023-03-02 20:29:51,745:INFO:       statsforecast: Not installed
2023-03-02 20:29:51,745:INFO:        tune_sklearn: Not installed
2023-03-02 20:29:51,746:INFO:                 ray: Not installed
2023-03-02 20:29:51,746:INFO:            hyperopt: Not installed
2023-03-02 20:29:51,746:INFO:              optuna: Not installed
2023-03-02 20:29:51,746:INFO:               skopt: Not installed
2023-03-02 20:29:51,746:INFO:              mlflow: Not installed
2023-03-02 20:29:51,746:INFO:              gradio: Not installed
2023-03-02 20:29:51,746:INFO:             fastapi: Not installed
2023-03-02 20:29:51,746:INFO:             uvicorn: Not installed
2023-03-02 20:29:51,746:INFO:              m2cgen: Not installed
2023-03-02 20:29:51,746:INFO:           evidently: Not installed
2023-03-02 20:29:51,746:INFO:               fugue: Not installed
2023-03-02 20:29:51,746:INFO:           streamlit: Not installed
2023-03-02 20:29:51,746:INFO:             prophet: Not installed
2023-03-02 20:29:51,746:INFO:None
2023-03-02 20:29:51,746:INFO:Set up data.
2023-03-02 20:29:51,761:INFO:Set up train/test split.
2023-03-02 20:29:51,771:INFO:Set up index.
2023-03-02 20:29:51,771:INFO:Set up folding strategy.
2023-03-02 20:29:51,771:INFO:Assigning column types.
2023-03-02 20:29:51,776:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-02 20:29:51,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-02 20:29:51,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:51,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:51,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:51,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-02 20:29:51,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:51,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:51,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:51,952:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-02 20:29:52,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:52,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-03-02 20:29:52,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,107:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-03-02 20:29:52,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,261:INFO:Preparing preprocessing pipeline...
2023-03-02 20:29:52,263:INFO:Set up simple imputation.
2023-03-02 20:29:52,268:INFO:Set up encoding of ordinal features.
2023-03-02 20:29:52,269:INFO:Set up encoding of categorical features.
2023-03-02 20:29:52,324:INFO:Finished creating preprocessing pipeline.
2023-03-02 20:29:52,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-03-02 20:29:52,338:INFO:Creating final display dataframe.
2023-03-02 20:29:52,617:INFO:Setup _display_container:                     Description             Value
0                    Session id               412
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 11)
5   Transformed train set shape         (623, 11)
6    Transformed test set shape         (268, 11)
7               Ignore features                 3
8              Ordinal features                 1
9              Numeric features                 6
10         Categorical features                 2
11     Rows with missing values             79.5%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              73f3
2023-03-02 20:29:52,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,699:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-02 20:29:52,777:INFO:setup() successfully completed in 1.04s...............
2023-03-02 20:30:04,439:INFO:Initializing compare_models()
2023-03-02 20:30:04,439:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-03-02 20:30:04,439:INFO:Checking exceptions
2023-03-02 20:30:04,446:INFO:Preparing display monitor
2023-03-02 20:30:04,482:INFO:Initializing Logistic Regression
2023-03-02 20:30:04,482:INFO:Total runtime is 3.445148468017578e-06 minutes
2023-03-02 20:30:04,487:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:04,487:INFO:Initializing create_model()
2023-03-02 20:30:04,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:04,488:INFO:Checking exceptions
2023-03-02 20:30:04,488:INFO:Importing libraries
2023-03-02 20:30:04,488:INFO:Copying training dataset
2023-03-02 20:30:04,494:INFO:Defining folds
2023-03-02 20:30:04,494:INFO:Declaring metric variables
2023-03-02 20:30:04,500:INFO:Importing untrained model
2023-03-02 20:30:04,505:INFO:Logistic Regression Imported successfully
2023-03-02 20:30:04,514:INFO:Starting cross validation
2023-03-02 20:30:04,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:06,294:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:30:06,306:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:30:06,363:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:30:06,778:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:30:06,800:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:30:06,912:INFO:Calculating mean and std
2023-03-02 20:30:06,913:INFO:Creating metrics dataframe
2023-03-02 20:30:06,917:INFO:Uploading results into container
2023-03-02 20:30:06,918:INFO:Uploading model into container now
2023-03-02 20:30:06,919:INFO:_master_model_container: 1
2023-03-02 20:30:06,919:INFO:_display_container: 2
2023-03-02 20:30:06,920:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:30:06,921:INFO:create_model() successfully completed......................................
2023-03-02 20:30:07,018:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:07,018:INFO:Creating metrics dataframe
2023-03-02 20:30:07,027:INFO:Initializing K Neighbors Classifier
2023-03-02 20:30:07,028:INFO:Total runtime is 0.042425584793090824 minutes
2023-03-02 20:30:07,031:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:07,031:INFO:Initializing create_model()
2023-03-02 20:30:07,031:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:07,031:INFO:Checking exceptions
2023-03-02 20:30:07,031:INFO:Importing libraries
2023-03-02 20:30:07,032:INFO:Copying training dataset
2023-03-02 20:30:07,036:INFO:Defining folds
2023-03-02 20:30:07,036:INFO:Declaring metric variables
2023-03-02 20:30:07,039:INFO:Importing untrained model
2023-03-02 20:30:07,044:INFO:K Neighbors Classifier Imported successfully
2023-03-02 20:30:07,053:INFO:Starting cross validation
2023-03-02 20:30:07,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:08,468:INFO:Calculating mean and std
2023-03-02 20:30:08,469:INFO:Creating metrics dataframe
2023-03-02 20:30:08,472:INFO:Uploading results into container
2023-03-02 20:30:08,473:INFO:Uploading model into container now
2023-03-02 20:30:08,473:INFO:_master_model_container: 2
2023-03-02 20:30:08,473:INFO:_display_container: 2
2023-03-02 20:30:08,473:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-03-02 20:30:08,474:INFO:create_model() successfully completed......................................
2023-03-02 20:30:08,547:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:08,547:INFO:Creating metrics dataframe
2023-03-02 20:30:08,556:INFO:Initializing Naive Bayes
2023-03-02 20:30:08,556:INFO:Total runtime is 0.06789526144663494 minutes
2023-03-02 20:30:08,559:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:08,559:INFO:Initializing create_model()
2023-03-02 20:30:08,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:08,559:INFO:Checking exceptions
2023-03-02 20:30:08,559:INFO:Importing libraries
2023-03-02 20:30:08,559:INFO:Copying training dataset
2023-03-02 20:30:08,563:INFO:Defining folds
2023-03-02 20:30:08,563:INFO:Declaring metric variables
2023-03-02 20:30:08,566:INFO:Importing untrained model
2023-03-02 20:30:08,568:INFO:Naive Bayes Imported successfully
2023-03-02 20:30:08,575:INFO:Starting cross validation
2023-03-02 20:30:08,576:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:08,877:INFO:Calculating mean and std
2023-03-02 20:30:08,877:INFO:Creating metrics dataframe
2023-03-02 20:30:08,881:INFO:Uploading results into container
2023-03-02 20:30:08,882:INFO:Uploading model into container now
2023-03-02 20:30:08,882:INFO:_master_model_container: 3
2023-03-02 20:30:08,882:INFO:_display_container: 2
2023-03-02 20:30:08,882:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-03-02 20:30:08,882:INFO:create_model() successfully completed......................................
2023-03-02 20:30:08,952:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:08,952:INFO:Creating metrics dataframe
2023-03-02 20:30:08,961:INFO:Initializing Decision Tree Classifier
2023-03-02 20:30:08,961:INFO:Total runtime is 0.07465527455012004 minutes
2023-03-02 20:30:08,964:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:08,964:INFO:Initializing create_model()
2023-03-02 20:30:08,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:08,964:INFO:Checking exceptions
2023-03-02 20:30:08,965:INFO:Importing libraries
2023-03-02 20:30:08,965:INFO:Copying training dataset
2023-03-02 20:30:08,968:INFO:Defining folds
2023-03-02 20:30:08,968:INFO:Declaring metric variables
2023-03-02 20:30:08,971:INFO:Importing untrained model
2023-03-02 20:30:08,973:INFO:Decision Tree Classifier Imported successfully
2023-03-02 20:30:08,979:INFO:Starting cross validation
2023-03-02 20:30:08,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:09,263:INFO:Calculating mean and std
2023-03-02 20:30:09,264:INFO:Creating metrics dataframe
2023-03-02 20:30:09,267:INFO:Uploading results into container
2023-03-02 20:30:09,268:INFO:Uploading model into container now
2023-03-02 20:30:09,268:INFO:_master_model_container: 4
2023-03-02 20:30:09,268:INFO:_display_container: 2
2023-03-02 20:30:09,268:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=412, splitter='best')
2023-03-02 20:30:09,269:INFO:create_model() successfully completed......................................
2023-03-02 20:30:09,350:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:09,350:INFO:Creating metrics dataframe
2023-03-02 20:30:09,360:INFO:Initializing SVM - Linear Kernel
2023-03-02 20:30:09,360:INFO:Total runtime is 0.08129491011301677 minutes
2023-03-02 20:30:09,363:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:09,363:INFO:Initializing create_model()
2023-03-02 20:30:09,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:09,364:INFO:Checking exceptions
2023-03-02 20:30:09,364:INFO:Importing libraries
2023-03-02 20:30:09,364:INFO:Copying training dataset
2023-03-02 20:30:09,368:INFO:Defining folds
2023-03-02 20:30:09,368:INFO:Declaring metric variables
2023-03-02 20:30:09,371:INFO:Importing untrained model
2023-03-02 20:30:09,376:INFO:SVM - Linear Kernel Imported successfully
2023-03-02 20:30:09,383:INFO:Starting cross validation
2023-03-02 20:30:09,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:09,579:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:09,636:INFO:Calculating mean and std
2023-03-02 20:30:09,637:INFO:Creating metrics dataframe
2023-03-02 20:30:09,640:INFO:Uploading results into container
2023-03-02 20:30:09,641:INFO:Uploading model into container now
2023-03-02 20:30:09,641:INFO:_master_model_container: 5
2023-03-02 20:30:09,641:INFO:_display_container: 2
2023-03-02 20:30:09,642:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=412, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-03-02 20:30:09,642:INFO:create_model() successfully completed......................................
2023-03-02 20:30:09,714:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:09,714:INFO:Creating metrics dataframe
2023-03-02 20:30:09,727:INFO:Initializing Ridge Classifier
2023-03-02 20:30:09,727:INFO:Total runtime is 0.08741246461868288 minutes
2023-03-02 20:30:09,730:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:09,730:INFO:Initializing create_model()
2023-03-02 20:30:09,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:09,730:INFO:Checking exceptions
2023-03-02 20:30:09,731:INFO:Importing libraries
2023-03-02 20:30:09,731:INFO:Copying training dataset
2023-03-02 20:30:09,734:INFO:Defining folds
2023-03-02 20:30:09,734:INFO:Declaring metric variables
2023-03-02 20:30:09,737:INFO:Importing untrained model
2023-03-02 20:30:09,741:INFO:Ridge Classifier Imported successfully
2023-03-02 20:30:09,749:INFO:Starting cross validation
2023-03-02 20:30:09,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:09,986:INFO:Calculating mean and std
2023-03-02 20:30:09,986:INFO:Creating metrics dataframe
2023-03-02 20:30:09,990:INFO:Uploading results into container
2023-03-02 20:30:09,990:INFO:Uploading model into container now
2023-03-02 20:30:09,991:INFO:_master_model_container: 6
2023-03-02 20:30:09,991:INFO:_display_container: 2
2023-03-02 20:30:09,991:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=412, solver='auto',
                tol=0.0001)
2023-03-02 20:30:09,991:INFO:create_model() successfully completed......................................
2023-03-02 20:30:10,062:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:10,062:INFO:Creating metrics dataframe
2023-03-02 20:30:10,072:INFO:Initializing Random Forest Classifier
2023-03-02 20:30:10,072:INFO:Total runtime is 0.0931709130605062 minutes
2023-03-02 20:30:10,075:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:10,076:INFO:Initializing create_model()
2023-03-02 20:30:10,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:10,076:INFO:Checking exceptions
2023-03-02 20:30:10,076:INFO:Importing libraries
2023-03-02 20:30:10,076:INFO:Copying training dataset
2023-03-02 20:30:10,080:INFO:Defining folds
2023-03-02 20:30:10,080:INFO:Declaring metric variables
2023-03-02 20:30:10,083:INFO:Importing untrained model
2023-03-02 20:30:10,086:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:30:10,092:INFO:Starting cross validation
2023-03-02 20:30:10,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:11,034:INFO:Calculating mean and std
2023-03-02 20:30:11,035:INFO:Creating metrics dataframe
2023-03-02 20:30:11,038:INFO:Uploading results into container
2023-03-02 20:30:11,038:INFO:Uploading model into container now
2023-03-02 20:30:11,039:INFO:_master_model_container: 7
2023-03-02 20:30:11,039:INFO:_display_container: 2
2023-03-02 20:30:11,040:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:30:11,040:INFO:create_model() successfully completed......................................
2023-03-02 20:30:11,118:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:11,118:INFO:Creating metrics dataframe
2023-03-02 20:30:11,128:INFO:Initializing Quadratic Discriminant Analysis
2023-03-02 20:30:11,128:INFO:Total runtime is 0.11077343622843426 minutes
2023-03-02 20:30:11,132:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:11,133:INFO:Initializing create_model()
2023-03-02 20:30:11,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:11,133:INFO:Checking exceptions
2023-03-02 20:30:11,133:INFO:Importing libraries
2023-03-02 20:30:11,133:INFO:Copying training dataset
2023-03-02 20:30:11,137:INFO:Defining folds
2023-03-02 20:30:11,137:INFO:Declaring metric variables
2023-03-02 20:30:11,141:INFO:Importing untrained model
2023-03-02 20:30:11,145:INFO:Quadratic Discriminant Analysis Imported successfully
2023-03-02 20:30:11,152:INFO:Starting cross validation
2023-03-02 20:30:11,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:11,284:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,286:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,297:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,302:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,304:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,304:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,307:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,308:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,316:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,329:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-03-02 20:30:11,456:INFO:Calculating mean and std
2023-03-02 20:30:11,457:INFO:Creating metrics dataframe
2023-03-02 20:30:11,460:INFO:Uploading results into container
2023-03-02 20:30:11,460:INFO:Uploading model into container now
2023-03-02 20:30:11,460:INFO:_master_model_container: 8
2023-03-02 20:30:11,461:INFO:_display_container: 2
2023-03-02 20:30:11,461:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-03-02 20:30:11,461:INFO:create_model() successfully completed......................................
2023-03-02 20:30:11,530:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:11,531:INFO:Creating metrics dataframe
2023-03-02 20:30:11,541:INFO:Initializing Ada Boost Classifier
2023-03-02 20:30:11,541:INFO:Total runtime is 0.11764646768569947 minutes
2023-03-02 20:30:11,544:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:11,544:INFO:Initializing create_model()
2023-03-02 20:30:11,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:11,544:INFO:Checking exceptions
2023-03-02 20:30:11,544:INFO:Importing libraries
2023-03-02 20:30:11,544:INFO:Copying training dataset
2023-03-02 20:30:11,548:INFO:Defining folds
2023-03-02 20:30:11,548:INFO:Declaring metric variables
2023-03-02 20:30:11,550:INFO:Importing untrained model
2023-03-02 20:30:11,553:INFO:Ada Boost Classifier Imported successfully
2023-03-02 20:30:11,559:INFO:Starting cross validation
2023-03-02 20:30:11,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:12,109:INFO:Calculating mean and std
2023-03-02 20:30:12,110:INFO:Creating metrics dataframe
2023-03-02 20:30:12,113:INFO:Uploading results into container
2023-03-02 20:30:12,114:INFO:Uploading model into container now
2023-03-02 20:30:12,114:INFO:_master_model_container: 9
2023-03-02 20:30:12,114:INFO:_display_container: 2
2023-03-02 20:30:12,115:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=412)
2023-03-02 20:30:12,115:INFO:create_model() successfully completed......................................
2023-03-02 20:30:12,187:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:12,187:INFO:Creating metrics dataframe
2023-03-02 20:30:12,198:INFO:Initializing Gradient Boosting Classifier
2023-03-02 20:30:12,198:INFO:Total runtime is 0.1285953998565674 minutes
2023-03-02 20:30:12,201:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:12,201:INFO:Initializing create_model()
2023-03-02 20:30:12,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:12,202:INFO:Checking exceptions
2023-03-02 20:30:12,202:INFO:Importing libraries
2023-03-02 20:30:12,202:INFO:Copying training dataset
2023-03-02 20:30:12,205:INFO:Defining folds
2023-03-02 20:30:12,205:INFO:Declaring metric variables
2023-03-02 20:30:12,208:INFO:Importing untrained model
2023-03-02 20:30:12,211:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:30:12,219:INFO:Starting cross validation
2023-03-02 20:30:12,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:12,864:INFO:Calculating mean and std
2023-03-02 20:30:12,865:INFO:Creating metrics dataframe
2023-03-02 20:30:12,871:INFO:Uploading results into container
2023-03-02 20:30:12,872:INFO:Uploading model into container now
2023-03-02 20:30:12,872:INFO:_master_model_container: 10
2023-03-02 20:30:12,872:INFO:_display_container: 2
2023-03-02 20:30:12,873:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:30:12,873:INFO:create_model() successfully completed......................................
2023-03-02 20:30:12,954:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:12,955:INFO:Creating metrics dataframe
2023-03-02 20:30:12,965:INFO:Initializing Linear Discriminant Analysis
2023-03-02 20:30:12,966:INFO:Total runtime is 0.14139311313629152 minutes
2023-03-02 20:30:12,969:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:12,969:INFO:Initializing create_model()
2023-03-02 20:30:12,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:12,969:INFO:Checking exceptions
2023-03-02 20:30:12,969:INFO:Importing libraries
2023-03-02 20:30:12,969:INFO:Copying training dataset
2023-03-02 20:30:12,972:INFO:Defining folds
2023-03-02 20:30:12,973:INFO:Declaring metric variables
2023-03-02 20:30:12,975:INFO:Importing untrained model
2023-03-02 20:30:12,978:INFO:Linear Discriminant Analysis Imported successfully
2023-03-02 20:30:12,984:INFO:Starting cross validation
2023-03-02 20:30:12,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:13,279:INFO:Calculating mean and std
2023-03-02 20:30:13,280:INFO:Creating metrics dataframe
2023-03-02 20:30:13,284:INFO:Uploading results into container
2023-03-02 20:30:13,284:INFO:Uploading model into container now
2023-03-02 20:30:13,284:INFO:_master_model_container: 11
2023-03-02 20:30:13,284:INFO:_display_container: 2
2023-03-02 20:30:13,285:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-03-02 20:30:13,285:INFO:create_model() successfully completed......................................
2023-03-02 20:30:13,356:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:13,356:INFO:Creating metrics dataframe
2023-03-02 20:30:13,368:INFO:Initializing Extra Trees Classifier
2023-03-02 20:30:13,368:INFO:Total runtime is 0.14809468587239585 minutes
2023-03-02 20:30:13,371:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:13,371:INFO:Initializing create_model()
2023-03-02 20:30:13,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:13,371:INFO:Checking exceptions
2023-03-02 20:30:13,371:INFO:Importing libraries
2023-03-02 20:30:13,371:INFO:Copying training dataset
2023-03-02 20:30:13,375:INFO:Defining folds
2023-03-02 20:30:13,375:INFO:Declaring metric variables
2023-03-02 20:30:13,378:INFO:Importing untrained model
2023-03-02 20:30:13,381:INFO:Extra Trees Classifier Imported successfully
2023-03-02 20:30:13,388:INFO:Starting cross validation
2023-03-02 20:30:13,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:14,272:INFO:Calculating mean and std
2023-03-02 20:30:14,274:INFO:Creating metrics dataframe
2023-03-02 20:30:14,278:INFO:Uploading results into container
2023-03-02 20:30:14,279:INFO:Uploading model into container now
2023-03-02 20:30:14,279:INFO:_master_model_container: 12
2023-03-02 20:30:14,279:INFO:_display_container: 2
2023-03-02 20:30:14,280:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=412, verbose=0, warm_start=False)
2023-03-02 20:30:14,280:INFO:create_model() successfully completed......................................
2023-03-02 20:30:14,371:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:14,371:INFO:Creating metrics dataframe
2023-03-02 20:30:14,383:INFO:Initializing Light Gradient Boosting Machine
2023-03-02 20:30:14,383:INFO:Total runtime is 0.16501631736755373 minutes
2023-03-02 20:30:14,386:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:14,386:INFO:Initializing create_model()
2023-03-02 20:30:14,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:14,387:INFO:Checking exceptions
2023-03-02 20:30:14,387:INFO:Importing libraries
2023-03-02 20:30:14,387:INFO:Copying training dataset
2023-03-02 20:30:14,391:INFO:Defining folds
2023-03-02 20:30:14,391:INFO:Declaring metric variables
2023-03-02 20:30:14,395:INFO:Importing untrained model
2023-03-02 20:30:14,399:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:30:14,407:INFO:Starting cross validation
2023-03-02 20:30:14,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:14,785:INFO:Calculating mean and std
2023-03-02 20:30:14,786:INFO:Creating metrics dataframe
2023-03-02 20:30:14,789:INFO:Uploading results into container
2023-03-02 20:30:14,790:INFO:Uploading model into container now
2023-03-02 20:30:14,790:INFO:_master_model_container: 13
2023-03-02 20:30:14,790:INFO:_display_container: 2
2023-03-02 20:30:14,790:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:30:14,791:INFO:create_model() successfully completed......................................
2023-03-02 20:30:14,860:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:14,860:INFO:Creating metrics dataframe
2023-03-02 20:30:14,871:INFO:Initializing Dummy Classifier
2023-03-02 20:30:14,872:INFO:Total runtime is 0.17315919399261476 minutes
2023-03-02 20:30:14,874:INFO:SubProcess create_model() called ==================================
2023-03-02 20:30:14,875:INFO:Initializing create_model()
2023-03-02 20:30:14,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222ec23e0>, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:14,875:INFO:Checking exceptions
2023-03-02 20:30:14,875:INFO:Importing libraries
2023-03-02 20:30:14,875:INFO:Copying training dataset
2023-03-02 20:30:14,878:INFO:Defining folds
2023-03-02 20:30:14,879:INFO:Declaring metric variables
2023-03-02 20:30:14,881:INFO:Importing untrained model
2023-03-02 20:30:14,885:INFO:Dummy Classifier Imported successfully
2023-03-02 20:30:14,890:INFO:Starting cross validation
2023-03-02 20:30:14,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:30:15,098:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,101:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,103:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,117:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,123:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,172:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,177:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,181:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,184:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,187:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:30:15,190:INFO:Calculating mean and std
2023-03-02 20:30:15,191:INFO:Creating metrics dataframe
2023-03-02 20:30:15,194:INFO:Uploading results into container
2023-03-02 20:30:15,195:INFO:Uploading model into container now
2023-03-02 20:30:15,195:INFO:_master_model_container: 14
2023-03-02 20:30:15,195:INFO:_display_container: 2
2023-03-02 20:30:15,195:INFO:DummyClassifier(constant=None, random_state=412, strategy='prior')
2023-03-02 20:30:15,195:INFO:create_model() successfully completed......................................
2023-03-02 20:30:15,279:INFO:SubProcess create_model() end ==================================
2023-03-02 20:30:15,280:INFO:Creating metrics dataframe
2023-03-02 20:30:15,299:INFO:Initializing create_model()
2023-03-02 20:30:15,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:30:15,299:INFO:Checking exceptions
2023-03-02 20:30:15,301:INFO:Importing libraries
2023-03-02 20:30:15,301:INFO:Copying training dataset
2023-03-02 20:30:15,304:INFO:Defining folds
2023-03-02 20:30:15,304:INFO:Declaring metric variables
2023-03-02 20:30:15,304:INFO:Importing untrained model
2023-03-02 20:30:15,305:INFO:Declaring custom model
2023-03-02 20:30:15,305:INFO:Extra Trees Classifier Imported successfully
2023-03-02 20:30:15,306:INFO:Cross validation set to False
2023-03-02 20:30:15,306:INFO:Fitting Model
2023-03-02 20:30:15,622:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=412, verbose=0, warm_start=False)
2023-03-02 20:30:15,622:INFO:create_model() successfully completed......................................
2023-03-02 20:30:15,719:INFO:_master_model_container: 14
2023-03-02 20:30:15,720:INFO:_display_container: 2
2023-03-02 20:30:15,720:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=412, verbose=0, warm_start=False)
2023-03-02 20:30:15,720:INFO:compare_models() successfully completed......................................
2023-03-02 20:31:13,484:INFO:Initializing create_model()
2023-03-02 20:31:13,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:31:13,485:INFO:Checking exceptions
2023-03-02 20:31:13,507:INFO:Importing libraries
2023-03-02 20:31:13,507:INFO:Copying training dataset
2023-03-02 20:31:13,512:INFO:Defining folds
2023-03-02 20:31:13,512:INFO:Declaring metric variables
2023-03-02 20:31:13,515:INFO:Importing untrained model
2023-03-02 20:31:13,519:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:31:13,527:INFO:Starting cross validation
2023-03-02 20:31:13,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:31:13,923:INFO:Calculating mean and std
2023-03-02 20:31:13,924:INFO:Creating metrics dataframe
2023-03-02 20:31:13,930:INFO:Finalizing model
2023-03-02 20:31:14,239:INFO:Uploading results into container
2023-03-02 20:31:14,241:INFO:Uploading model into container now
2023-03-02 20:31:14,249:INFO:_master_model_container: 15
2023-03-02 20:31:14,249:INFO:_display_container: 3
2023-03-02 20:31:14,250:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:31:14,250:INFO:create_model() successfully completed......................................
2023-03-02 20:31:27,654:INFO:Initializing tune_model()
2023-03-02 20:31:27,654:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:31:27,654:INFO:Checking exceptions
2023-03-02 20:31:27,678:INFO:Copying training dataset
2023-03-02 20:31:27,682:INFO:Checking base model
2023-03-02 20:31:27,683:INFO:Base model : Light Gradient Boosting Machine
2023-03-02 20:31:27,688:INFO:Declaring metric variables
2023-03-02 20:31:27,693:INFO:Defining Hyperparameters
2023-03-02 20:31:27,779:INFO:Tuning with n_jobs=-1
2023-03-02 20:31:27,780:INFO:Initializing RandomizedSearchCV
2023-03-02 20:31:29,562:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 46, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.6}
2023-03-02 20:31:29,563:INFO:Hyperparameter search completed
2023-03-02 20:31:29,563:INFO:SubProcess create_model() called ==================================
2023-03-02 20:31:29,564:INFO:Initializing create_model()
2023-03-02 20:31:29,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f22239cbd60>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 260, 'min_split_gain': 0.6, 'min_child_samples': 46, 'learning_rate': 0.2, 'feature_fraction': 0.8, 'bagging_freq': 0, 'bagging_fraction': 0.6})
2023-03-02 20:31:29,565:INFO:Checking exceptions
2023-03-02 20:31:29,565:INFO:Importing libraries
2023-03-02 20:31:29,565:INFO:Copying training dataset
2023-03-02 20:31:29,571:INFO:Defining folds
2023-03-02 20:31:29,571:INFO:Declaring metric variables
2023-03-02 20:31:29,576:INFO:Importing untrained model
2023-03-02 20:31:29,576:INFO:Declaring custom model
2023-03-02 20:31:29,582:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:31:29,591:INFO:Starting cross validation
2023-03-02 20:31:29,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:31:29,962:INFO:Calculating mean and std
2023-03-02 20:31:29,963:INFO:Creating metrics dataframe
2023-03-02 20:31:29,968:INFO:Finalizing model
2023-03-02 20:31:30,067:INFO:Uploading results into container
2023-03-02 20:31:30,068:INFO:Uploading model into container now
2023-03-02 20:31:30,068:INFO:_master_model_container: 16
2023-03-02 20:31:30,068:INFO:_display_container: 4
2023-03-02 20:31:30,069:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:31:30,069:INFO:create_model() successfully completed......................................
2023-03-02 20:31:30,144:INFO:SubProcess create_model() end ==================================
2023-03-02 20:31:30,144:INFO:choose_better activated
2023-03-02 20:31:30,148:INFO:SubProcess create_model() called ==================================
2023-03-02 20:31:30,148:INFO:Initializing create_model()
2023-03-02 20:31:30,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:31:30,149:INFO:Checking exceptions
2023-03-02 20:31:30,150:INFO:Importing libraries
2023-03-02 20:31:30,151:INFO:Copying training dataset
2023-03-02 20:31:30,155:INFO:Defining folds
2023-03-02 20:31:30,155:INFO:Declaring metric variables
2023-03-02 20:31:30,155:INFO:Importing untrained model
2023-03-02 20:31:30,155:INFO:Declaring custom model
2023-03-02 20:31:30,156:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:31:30,156:INFO:Starting cross validation
2023-03-02 20:31:30,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:31:30,514:INFO:Calculating mean and std
2023-03-02 20:31:30,514:INFO:Creating metrics dataframe
2023-03-02 20:31:30,517:INFO:Finalizing model
2023-03-02 20:31:30,618:INFO:Uploading results into container
2023-03-02 20:31:30,619:INFO:Uploading model into container now
2023-03-02 20:31:30,619:INFO:_master_model_container: 17
2023-03-02 20:31:30,619:INFO:_display_container: 5
2023-03-02 20:31:30,620:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:31:30,620:INFO:create_model() successfully completed......................................
2023-03-02 20:31:30,691:INFO:SubProcess create_model() end ==================================
2023-03-02 20:31:30,692:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8041
2023-03-02 20:31:30,693:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8219
2023-03-02 20:31:30,693:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-03-02 20:31:30,693:INFO:choose_better completed
2023-03-02 20:31:30,701:INFO:_master_model_container: 17
2023-03-02 20:31:30,701:INFO:_display_container: 4
2023-03-02 20:31:30,701:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:31:30,701:INFO:tune_model() successfully completed......................................
2023-03-02 20:31:40,435:INFO:Initializing plot_model()
2023-03-02 20:31:40,435:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:31:40,436:INFO:Checking exceptions
2023-03-02 20:31:40,443:INFO:Preloading libraries
2023-03-02 20:31:40,455:INFO:Copying training dataset
2023-03-02 20:31:40,456:INFO:Plot type: learning
2023-03-02 20:31:40,628:INFO:Fitting Model
2023-03-02 20:31:41,108:INFO:Visual Rendered Successfully
2023-03-02 20:31:41,179:INFO:plot_model() successfully completed......................................
2023-03-02 20:32:45,689:INFO:Initializing plot_model()
2023-03-02 20:32:45,689:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=46, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=260, n_jobs=-1, num_leaves=150, objective=None,
               random_state=412, reg_alpha=0.005, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:32:45,689:INFO:Checking exceptions
2023-03-02 20:32:45,694:INFO:Preloading libraries
2023-03-02 20:32:45,699:INFO:Copying training dataset
2023-03-02 20:32:45,699:INFO:Plot type: auc
2023-03-02 20:32:45,869:INFO:Fitting Model
2023-03-02 20:32:45,869:INFO:Scoring test/hold-out set
2023-03-02 20:32:46,031:INFO:Visual Rendered Successfully
2023-03-02 20:32:46,107:INFO:plot_model() successfully completed......................................
2023-03-02 20:34:12,652:INFO:Initializing tune_model()
2023-03-02 20:34:12,652:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:34:12,652:INFO:Checking exceptions
2023-03-02 20:34:12,676:INFO:Copying training dataset
2023-03-02 20:34:12,681:INFO:Checking base model
2023-03-02 20:34:12,681:INFO:Base model : Light Gradient Boosting Machine
2023-03-02 20:34:12,686:INFO:Declaring metric variables
2023-03-02 20:34:12,691:INFO:Defining Hyperparameters
2023-03-02 20:34:12,791:INFO:Tuning with n_jobs=-1
2023-03-02 20:34:12,792:INFO:Initializing RandomizedSearchCV
2023-03-02 20:34:14,574:INFO:best_params: {'actual_estimator__reg_lambda': 0.4, 'actual_estimator__reg_alpha': 0.7, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 250, 'actual_estimator__min_split_gain': 0.6, 'actual_estimator__min_child_samples': 11, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.8}
2023-03-02 20:34:14,574:INFO:Hyperparameter search completed
2023-03-02 20:34:14,575:INFO:SubProcess create_model() called ==================================
2023-03-02 20:34:14,575:INFO:Initializing create_model()
2023-03-02 20:34:14,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222fe8b80>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.4, 'reg_alpha': 0.7, 'num_leaves': 80, 'n_estimators': 250, 'min_split_gain': 0.6, 'min_child_samples': 11, 'learning_rate': 0.001, 'feature_fraction': 0.7, 'bagging_freq': 4, 'bagging_fraction': 0.8})
2023-03-02 20:34:14,575:INFO:Checking exceptions
2023-03-02 20:34:14,575:INFO:Importing libraries
2023-03-02 20:34:14,576:INFO:Copying training dataset
2023-03-02 20:34:14,579:INFO:Defining folds
2023-03-02 20:34:14,579:INFO:Declaring metric variables
2023-03-02 20:34:14,582:INFO:Importing untrained model
2023-03-02 20:34:14,582:INFO:Declaring custom model
2023-03-02 20:34:14,587:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:34:14,596:INFO:Starting cross validation
2023-03-02 20:34:14,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:34:14,864:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,881:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,889:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,894:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,934:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,955:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,958:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,967:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,968:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,974:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-03-02 20:34:14,977:INFO:Calculating mean and std
2023-03-02 20:34:14,978:INFO:Creating metrics dataframe
2023-03-02 20:34:14,983:INFO:Finalizing model
2023-03-02 20:34:15,081:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2023-03-02 20:34:15,081:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2023-03-02 20:34:15,081:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-03-02 20:34:15,215:INFO:Uploading results into container
2023-03-02 20:34:15,215:INFO:Uploading model into container now
2023-03-02 20:34:15,216:INFO:_master_model_container: 18
2023-03-02 20:34:15,216:INFO:_display_container: 5
2023-03-02 20:34:15,216:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=250, n_jobs=-1, num_leaves=80, objective=None,
               random_state=412, reg_alpha=0.7, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:34:15,216:INFO:create_model() successfully completed......................................
2023-03-02 20:34:15,287:INFO:SubProcess create_model() end ==================================
2023-03-02 20:34:15,287:INFO:choose_better activated
2023-03-02 20:34:15,290:INFO:SubProcess create_model() called ==================================
2023-03-02 20:34:15,290:INFO:Initializing create_model()
2023-03-02 20:34:15,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:34:15,291:INFO:Checking exceptions
2023-03-02 20:34:15,292:INFO:Importing libraries
2023-03-02 20:34:15,292:INFO:Copying training dataset
2023-03-02 20:34:15,295:INFO:Defining folds
2023-03-02 20:34:15,295:INFO:Declaring metric variables
2023-03-02 20:34:15,296:INFO:Importing untrained model
2023-03-02 20:34:15,296:INFO:Declaring custom model
2023-03-02 20:34:15,296:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-02 20:34:15,296:INFO:Starting cross validation
2023-03-02 20:34:15,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:34:15,641:INFO:Calculating mean and std
2023-03-02 20:34:15,642:INFO:Creating metrics dataframe
2023-03-02 20:34:15,644:INFO:Finalizing model
2023-03-02 20:34:15,752:INFO:Uploading results into container
2023-03-02 20:34:15,752:INFO:Uploading model into container now
2023-03-02 20:34:15,752:INFO:_master_model_container: 19
2023-03-02 20:34:15,752:INFO:_display_container: 6
2023-03-02 20:34:15,753:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:34:15,753:INFO:create_model() successfully completed......................................
2023-03-02 20:34:15,830:INFO:SubProcess create_model() end ==================================
2023-03-02 20:34:15,831:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=412, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8391
2023-03-02 20:34:15,831:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=250, n_jobs=-1, num_leaves=80, objective=None,
               random_state=412, reg_alpha=0.7, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8545
2023-03-02 20:34:15,832:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=250, n_jobs=-1, num_leaves=80, objective=None,
               random_state=412, reg_alpha=0.7, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-03-02 20:34:15,832:INFO:choose_better completed
2023-03-02 20:34:15,840:INFO:_master_model_container: 19
2023-03-02 20:34:15,840:INFO:_display_container: 5
2023-03-02 20:34:15,841:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=11, min_child_weight=0.001, min_split_gain=0.6,
               n_estimators=250, n_jobs=-1, num_leaves=80, objective=None,
               random_state=412, reg_alpha=0.7, reg_lambda=0.4, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-03-02 20:34:15,841:INFO:tune_model() successfully completed......................................
2023-03-02 20:36:53,402:INFO:Initializing create_model()
2023-03-02 20:36:53,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:36:53,402:INFO:Checking exceptions
2023-03-02 20:36:53,419:INFO:Importing libraries
2023-03-02 20:36:53,419:INFO:Copying training dataset
2023-03-02 20:36:53,426:INFO:Defining folds
2023-03-02 20:36:53,426:INFO:Declaring metric variables
2023-03-02 20:36:53,431:INFO:Importing untrained model
2023-03-02 20:36:53,436:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:36:53,442:INFO:Starting cross validation
2023-03-02 20:36:53,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:36:53,967:INFO:Calculating mean and std
2023-03-02 20:36:53,968:INFO:Creating metrics dataframe
2023-03-02 20:36:53,972:INFO:Finalizing model
2023-03-02 20:36:54,388:INFO:Uploading results into container
2023-03-02 20:36:54,389:INFO:Uploading model into container now
2023-03-02 20:36:54,399:INFO:_master_model_container: 20
2023-03-02 20:36:54,399:INFO:_display_container: 6
2023-03-02 20:36:54,399:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:36:54,399:INFO:create_model() successfully completed......................................
2023-03-02 20:37:52,966:INFO:Initializing create_model()
2023-03-02 20:37:52,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:37:52,967:INFO:Checking exceptions
2023-03-02 20:37:52,995:INFO:Importing libraries
2023-03-02 20:37:52,995:INFO:Copying training dataset
2023-03-02 20:37:53,003:INFO:Defining folds
2023-03-02 20:37:53,003:INFO:Declaring metric variables
2023-03-02 20:37:53,011:INFO:Importing untrained model
2023-03-02 20:37:53,016:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:37:53,028:INFO:Starting cross validation
2023-03-02 20:37:53,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:37:53,608:INFO:Calculating mean and std
2023-03-02 20:37:53,608:INFO:Creating metrics dataframe
2023-03-02 20:37:53,613:INFO:Finalizing model
2023-03-02 20:37:53,722:INFO:Uploading results into container
2023-03-02 20:37:53,722:INFO:Uploading model into container now
2023-03-02 20:37:53,730:INFO:_master_model_container: 21
2023-03-02 20:37:53,730:INFO:_display_container: 7
2023-03-02 20:37:53,731:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:37:53,731:INFO:create_model() successfully completed......................................
2023-03-02 20:37:55,879:INFO:Initializing tune_model()
2023-03-02 20:37:55,880:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:37:55,880:INFO:Checking exceptions
2023-03-02 20:37:55,903:INFO:Copying training dataset
2023-03-02 20:37:55,908:INFO:Checking base model
2023-03-02 20:37:55,909:INFO:Base model : Random Forest Classifier
2023-03-02 20:37:55,915:INFO:Declaring metric variables
2023-03-02 20:37:55,921:INFO:Defining Hyperparameters
2023-03-02 20:37:56,012:INFO:Tuning with n_jobs=-1
2023-03-02 20:37:56,012:INFO:Initializing RandomizedSearchCV
2023-03-02 20:38:04,274:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2023-03-02 20:38:04,274:INFO:Hyperparameter search completed
2023-03-02 20:38:04,274:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:04,275:INFO:Initializing create_model()
2023-03-02 20:38:04,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2222041150>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.005, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2023-03-02 20:38:04,275:INFO:Checking exceptions
2023-03-02 20:38:04,275:INFO:Importing libraries
2023-03-02 20:38:04,275:INFO:Copying training dataset
2023-03-02 20:38:04,281:INFO:Defining folds
2023-03-02 20:38:04,281:INFO:Declaring metric variables
2023-03-02 20:38:04,284:INFO:Importing untrained model
2023-03-02 20:38:04,285:INFO:Declaring custom model
2023-03-02 20:38:04,288:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:04,293:INFO:Starting cross validation
2023-03-02 20:38:04,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:05,114:INFO:Calculating mean and std
2023-03-02 20:38:05,115:INFO:Creating metrics dataframe
2023-03-02 20:38:05,120:INFO:Finalizing model
2023-03-02 20:38:05,814:INFO:Uploading results into container
2023-03-02 20:38:05,815:INFO:Uploading model into container now
2023-03-02 20:38:05,816:INFO:_master_model_container: 22
2023-03-02 20:38:05,816:INFO:_display_container: 8
2023-03-02 20:38:05,816:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:05,816:INFO:create_model() successfully completed......................................
2023-03-02 20:38:05,891:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:05,891:INFO:choose_better activated
2023-03-02 20:38:05,894:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:05,895:INFO:Initializing create_model()
2023-03-02 20:38:05,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:38:05,895:INFO:Checking exceptions
2023-03-02 20:38:05,897:INFO:Importing libraries
2023-03-02 20:38:05,897:INFO:Copying training dataset
2023-03-02 20:38:05,901:INFO:Defining folds
2023-03-02 20:38:05,901:INFO:Declaring metric variables
2023-03-02 20:38:05,901:INFO:Importing untrained model
2023-03-02 20:38:05,901:INFO:Declaring custom model
2023-03-02 20:38:05,901:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:05,902:INFO:Starting cross validation
2023-03-02 20:38:05,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:06,448:INFO:Calculating mean and std
2023-03-02 20:38:06,449:INFO:Creating metrics dataframe
2023-03-02 20:38:06,450:INFO:Finalizing model
2023-03-02 20:38:06,542:INFO:Uploading results into container
2023-03-02 20:38:06,543:INFO:Uploading model into container now
2023-03-02 20:38:06,543:INFO:_master_model_container: 23
2023-03-02 20:38:06,543:INFO:_display_container: 9
2023-03-02 20:38:06,544:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:06,544:INFO:create_model() successfully completed......................................
2023-03-02 20:38:06,614:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:06,615:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.857
2023-03-02 20:38:06,615:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.8589
2023-03-02 20:38:06,615:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) is best model
2023-03-02 20:38:06,615:INFO:choose_better completed
2023-03-02 20:38:06,624:INFO:_master_model_container: 23
2023-03-02 20:38:06,624:INFO:_display_container: 8
2023-03-02 20:38:06,624:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:06,624:INFO:tune_model() successfully completed......................................
2023-03-02 20:38:21,771:INFO:Initializing tune_model()
2023-03-02 20:38:21,772:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:38:21,772:INFO:Checking exceptions
2023-03-02 20:38:21,792:INFO:Copying training dataset
2023-03-02 20:38:21,796:INFO:Checking base model
2023-03-02 20:38:21,796:INFO:Base model : Random Forest Classifier
2023-03-02 20:38:21,800:INFO:Declaring metric variables
2023-03-02 20:38:21,803:INFO:Defining Hyperparameters
2023-03-02 20:38:21,893:INFO:Tuning with n_jobs=-1
2023-03-02 20:38:21,893:INFO:Initializing RandomizedSearchCV
2023-03-02 20:38:25,429:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2023-03-02 20:38:25,430:INFO:Hyperparameter search completed
2023-03-02 20:38:25,430:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:25,430:INFO:Initializing create_model()
2023-03-02 20:38:25,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f222310e3b0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.005, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2023-03-02 20:38:25,430:INFO:Checking exceptions
2023-03-02 20:38:25,431:INFO:Importing libraries
2023-03-02 20:38:25,431:INFO:Copying training dataset
2023-03-02 20:38:25,435:INFO:Defining folds
2023-03-02 20:38:25,435:INFO:Declaring metric variables
2023-03-02 20:38:25,438:INFO:Importing untrained model
2023-03-02 20:38:25,438:INFO:Declaring custom model
2023-03-02 20:38:25,443:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:25,449:INFO:Starting cross validation
2023-03-02 20:38:25,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:26,292:INFO:Calculating mean and std
2023-03-02 20:38:26,293:INFO:Creating metrics dataframe
2023-03-02 20:38:26,298:INFO:Finalizing model
2023-03-02 20:38:26,422:INFO:Uploading results into container
2023-03-02 20:38:26,423:INFO:Uploading model into container now
2023-03-02 20:38:26,423:INFO:_master_model_container: 24
2023-03-02 20:38:26,423:INFO:_display_container: 9
2023-03-02 20:38:26,424:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:26,424:INFO:create_model() successfully completed......................................
2023-03-02 20:38:26,496:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:26,496:INFO:choose_better activated
2023-03-02 20:38:26,499:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:26,499:INFO:Initializing create_model()
2023-03-02 20:38:26,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:38:26,499:INFO:Checking exceptions
2023-03-02 20:38:26,501:INFO:Importing libraries
2023-03-02 20:38:26,501:INFO:Copying training dataset
2023-03-02 20:38:26,504:INFO:Defining folds
2023-03-02 20:38:26,504:INFO:Declaring metric variables
2023-03-02 20:38:26,504:INFO:Importing untrained model
2023-03-02 20:38:26,505:INFO:Declaring custom model
2023-03-02 20:38:26,505:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:26,505:INFO:Starting cross validation
2023-03-02 20:38:26,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:27,094:INFO:Calculating mean and std
2023-03-02 20:38:27,094:INFO:Creating metrics dataframe
2023-03-02 20:38:27,096:INFO:Finalizing model
2023-03-02 20:38:27,189:INFO:Uploading results into container
2023-03-02 20:38:27,189:INFO:Uploading model into container now
2023-03-02 20:38:27,190:INFO:_master_model_container: 25
2023-03-02 20:38:27,190:INFO:_display_container: 10
2023-03-02 20:38:27,190:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:27,190:INFO:create_model() successfully completed......................................
2023-03-02 20:38:27,261:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:27,261:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.857
2023-03-02 20:38:27,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.8589
2023-03-02 20:38:27,262:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) is best model
2023-03-02 20:38:27,262:INFO:choose_better completed
2023-03-02 20:38:27,271:INFO:_master_model_container: 25
2023-03-02 20:38:27,271:INFO:_display_container: 9
2023-03-02 20:38:27,272:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:27,272:INFO:tune_model() successfully completed......................................
2023-03-02 20:38:47,296:INFO:Initializing tune_model()
2023-03-02 20:38:47,297:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:38:47,297:INFO:Checking exceptions
2023-03-02 20:38:47,325:INFO:Copying training dataset
2023-03-02 20:38:47,330:INFO:Checking base model
2023-03-02 20:38:47,330:INFO:Base model : Random Forest Classifier
2023-03-02 20:38:47,335:INFO:Declaring metric variables
2023-03-02 20:38:47,340:INFO:Defining Hyperparameters
2023-03-02 20:38:47,422:INFO:Tuning with n_jobs=-1
2023-03-02 20:38:47,423:INFO:Initializing RandomizedSearchCV
2023-03-02 20:38:50,922:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'entropy', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2023-03-02 20:38:50,923:INFO:Hyperparameter search completed
2023-03-02 20:38:50,923:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:50,924:INFO:Initializing create_model()
2023-03-02 20:38:50,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f22230f5f90>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.005, 'max_features': 'log2', 'max_depth': 11, 'criterion': 'entropy', 'class_weight': 'balanced', 'bootstrap': True})
2023-03-02 20:38:50,924:INFO:Checking exceptions
2023-03-02 20:38:50,924:INFO:Importing libraries
2023-03-02 20:38:50,924:INFO:Copying training dataset
2023-03-02 20:38:50,929:INFO:Defining folds
2023-03-02 20:38:50,929:INFO:Declaring metric variables
2023-03-02 20:38:50,932:INFO:Importing untrained model
2023-03-02 20:38:50,932:INFO:Declaring custom model
2023-03-02 20:38:50,936:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:50,942:INFO:Starting cross validation
2023-03-02 20:38:50,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:51,761:INFO:Calculating mean and std
2023-03-02 20:38:51,762:INFO:Creating metrics dataframe
2023-03-02 20:38:51,767:INFO:Finalizing model
2023-03-02 20:38:51,905:INFO:Uploading results into container
2023-03-02 20:38:51,906:INFO:Uploading model into container now
2023-03-02 20:38:51,906:INFO:_master_model_container: 26
2023-03-02 20:38:51,906:INFO:_display_container: 10
2023-03-02 20:38:51,907:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:51,907:INFO:create_model() successfully completed......................................
2023-03-02 20:38:51,981:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:51,981:INFO:choose_better activated
2023-03-02 20:38:51,984:INFO:SubProcess create_model() called ==================================
2023-03-02 20:38:51,985:INFO:Initializing create_model()
2023-03-02 20:38:51,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:38:51,985:INFO:Checking exceptions
2023-03-02 20:38:51,987:INFO:Importing libraries
2023-03-02 20:38:51,987:INFO:Copying training dataset
2023-03-02 20:38:51,990:INFO:Defining folds
2023-03-02 20:38:51,990:INFO:Declaring metric variables
2023-03-02 20:38:51,990:INFO:Importing untrained model
2023-03-02 20:38:51,990:INFO:Declaring custom model
2023-03-02 20:38:51,991:INFO:Random Forest Classifier Imported successfully
2023-03-02 20:38:51,991:INFO:Starting cross validation
2023-03-02 20:38:51,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:38:52,521:INFO:Calculating mean and std
2023-03-02 20:38:52,521:INFO:Creating metrics dataframe
2023-03-02 20:38:52,523:INFO:Finalizing model
2023-03-02 20:38:52,617:INFO:Uploading results into container
2023-03-02 20:38:52,617:INFO:Uploading model into container now
2023-03-02 20:38:52,618:INFO:_master_model_container: 27
2023-03-02 20:38:52,618:INFO:_display_container: 11
2023-03-02 20:38:52,618:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:52,618:INFO:create_model() successfully completed......................................
2023-03-02 20:38:52,695:INFO:SubProcess create_model() end ==================================
2023-03-02 20:38:52,695:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.857
2023-03-02 20:38:52,696:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) result for AUC is 0.8589
2023-03-02 20:38:52,696:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False) is best model
2023-03-02 20:38:52,696:INFO:choose_better completed
2023-03-02 20:38:52,704:INFO:_master_model_container: 27
2023-03-02 20:38:52,704:INFO:_display_container: 10
2023-03-02 20:38:52,705:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 20:38:52,705:INFO:tune_model() successfully completed......................................
2023-03-02 20:38:55,165:INFO:Initializing plot_model()
2023-03-02 20:38:55,165:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:38:55,166:INFO:Checking exceptions
2023-03-02 20:38:55,191:INFO:Preloading libraries
2023-03-02 20:38:55,205:INFO:Copying training dataset
2023-03-02 20:38:55,206:INFO:Plot type: learning
2023-03-02 20:38:55,357:INFO:Fitting Model
2023-03-02 20:39:00,463:INFO:Visual Rendered Successfully
2023-03-02 20:39:00,538:INFO:plot_model() successfully completed......................................
2023-03-02 20:39:07,676:INFO:Initializing plot_model()
2023-03-02 20:39:07,676:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:39:07,677:INFO:Checking exceptions
2023-03-02 20:39:07,712:INFO:Preloading libraries
2023-03-02 20:39:07,728:INFO:Copying training dataset
2023-03-02 20:39:07,728:INFO:Plot type: auc
2023-03-02 20:39:07,878:INFO:Fitting Model
2023-03-02 20:39:07,878:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:39:07,879:INFO:Scoring test/hold-out set
2023-03-02 20:39:08,144:INFO:Visual Rendered Successfully
2023-03-02 20:39:08,225:INFO:plot_model() successfully completed......................................
2023-03-02 20:39:43,541:INFO:Initializing create_model()
2023-03-02 20:39:43,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:39:43,541:INFO:Checking exceptions
2023-03-02 20:39:43,566:INFO:Importing libraries
2023-03-02 20:39:43,566:INFO:Copying training dataset
2023-03-02 20:39:43,573:INFO:Defining folds
2023-03-02 20:39:43,573:INFO:Declaring metric variables
2023-03-02 20:39:43,578:INFO:Importing untrained model
2023-03-02 20:39:43,584:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:39:43,594:INFO:Starting cross validation
2023-03-02 20:39:43,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:39:44,063:INFO:Calculating mean and std
2023-03-02 20:39:44,064:INFO:Creating metrics dataframe
2023-03-02 20:39:44,071:INFO:Finalizing model
2023-03-02 20:39:44,304:INFO:Uploading results into container
2023-03-02 20:39:44,305:INFO:Uploading model into container now
2023-03-02 20:39:44,314:INFO:_master_model_container: 28
2023-03-02 20:39:44,315:INFO:_display_container: 11
2023-03-02 20:39:44,315:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:39:44,315:INFO:create_model() successfully completed......................................
2023-03-02 20:40:06,115:INFO:Initializing tune_model()
2023-03-02 20:40:06,116:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:40:06,117:INFO:Checking exceptions
2023-03-02 20:40:06,152:INFO:Copying training dataset
2023-03-02 20:40:06,156:INFO:Checking base model
2023-03-02 20:40:06,156:INFO:Base model : Gradient Boosting Classifier
2023-03-02 20:40:06,161:INFO:Declaring metric variables
2023-03-02 20:40:06,165:INFO:Defining Hyperparameters
2023-03-02 20:40:06,256:INFO:Tuning with n_jobs=-1
2023-03-02 20:40:06,257:INFO:Initializing RandomizedSearchCV
2023-03-02 20:40:11,281:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.01}
2023-03-02 20:40:11,282:INFO:Hyperparameter search completed
2023-03-02 20:40:11,282:INFO:SubProcess create_model() called ==================================
2023-03-02 20:40:11,283:INFO:Initializing create_model()
2023-03-02 20:40:11,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f22222ff760>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.01})
2023-03-02 20:40:11,283:INFO:Checking exceptions
2023-03-02 20:40:11,284:INFO:Importing libraries
2023-03-02 20:40:11,284:INFO:Copying training dataset
2023-03-02 20:40:11,290:INFO:Defining folds
2023-03-02 20:40:11,290:INFO:Declaring metric variables
2023-03-02 20:40:11,294:INFO:Importing untrained model
2023-03-02 20:40:11,295:INFO:Declaring custom model
2023-03-02 20:40:11,300:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:40:11,309:INFO:Starting cross validation
2023-03-02 20:40:11,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:40:11,877:INFO:Calculating mean and std
2023-03-02 20:40:11,878:INFO:Creating metrics dataframe
2023-03-02 20:40:11,884:INFO:Finalizing model
2023-03-02 20:40:12,183:INFO:Uploading results into container
2023-03-02 20:40:12,184:INFO:Uploading model into container now
2023-03-02 20:40:12,184:INFO:_master_model_container: 29
2023-03-02 20:40:12,184:INFO:_display_container: 12
2023-03-02 20:40:12,185:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:12,185:INFO:create_model() successfully completed......................................
2023-03-02 20:40:12,258:INFO:SubProcess create_model() end ==================================
2023-03-02 20:40:12,258:INFO:choose_better activated
2023-03-02 20:40:12,261:INFO:SubProcess create_model() called ==================================
2023-03-02 20:40:12,261:INFO:Initializing create_model()
2023-03-02 20:40:12,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:40:12,262:INFO:Checking exceptions
2023-03-02 20:40:12,263:INFO:Importing libraries
2023-03-02 20:40:12,263:INFO:Copying training dataset
2023-03-02 20:40:12,266:INFO:Defining folds
2023-03-02 20:40:12,266:INFO:Declaring metric variables
2023-03-02 20:40:12,266:INFO:Importing untrained model
2023-03-02 20:40:12,266:INFO:Declaring custom model
2023-03-02 20:40:12,267:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:40:12,267:INFO:Starting cross validation
2023-03-02 20:40:12,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:40:12,700:INFO:Calculating mean and std
2023-03-02 20:40:12,701:INFO:Creating metrics dataframe
2023-03-02 20:40:12,702:INFO:Finalizing model
2023-03-02 20:40:12,772:INFO:Uploading results into container
2023-03-02 20:40:12,773:INFO:Uploading model into container now
2023-03-02 20:40:12,773:INFO:_master_model_container: 30
2023-03-02 20:40:12,773:INFO:_display_container: 13
2023-03-02 20:40:12,774:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:12,774:INFO:create_model() successfully completed......................................
2023-03-02 20:40:12,845:INFO:SubProcess create_model() end ==================================
2023-03-02 20:40:12,846:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8558
2023-03-02 20:40:12,846:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8567
2023-03-02 20:40:12,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-03-02 20:40:12,847:INFO:choose_better completed
2023-03-02 20:40:12,855:INFO:_master_model_container: 30
2023-03-02 20:40:12,855:INFO:_display_container: 12
2023-03-02 20:40:12,856:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:12,856:INFO:tune_model() successfully completed......................................
2023-03-02 20:40:31,499:INFO:Initializing tune_model()
2023-03-02 20:40:31,499:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:40:31,499:INFO:Checking exceptions
2023-03-02 20:40:31,522:INFO:Copying training dataset
2023-03-02 20:40:31,526:INFO:Checking base model
2023-03-02 20:40:31,527:INFO:Base model : Gradient Boosting Classifier
2023-03-02 20:40:31,532:INFO:Declaring metric variables
2023-03-02 20:40:31,537:INFO:Defining Hyperparameters
2023-03-02 20:40:31,624:INFO:Tuning with n_jobs=-1
2023-03-02 20:40:31,624:INFO:Initializing RandomizedSearchCV
2023-03-02 20:40:33,867:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__learning_rate': 0.01}
2023-03-02 20:40:33,868:INFO:Hyperparameter search completed
2023-03-02 20:40:33,868:INFO:SubProcess create_model() called ==================================
2023-03-02 20:40:33,869:INFO:Initializing create_model()
2023-03-02 20:40:33,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f22230fd2a0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.2, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.01})
2023-03-02 20:40:33,870:INFO:Checking exceptions
2023-03-02 20:40:33,870:INFO:Importing libraries
2023-03-02 20:40:33,870:INFO:Copying training dataset
2023-03-02 20:40:33,874:INFO:Defining folds
2023-03-02 20:40:33,874:INFO:Declaring metric variables
2023-03-02 20:40:33,877:INFO:Importing untrained model
2023-03-02 20:40:33,877:INFO:Declaring custom model
2023-03-02 20:40:33,880:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:40:33,886:INFO:Starting cross validation
2023-03-02 20:40:33,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:40:34,415:INFO:Calculating mean and std
2023-03-02 20:40:34,416:INFO:Creating metrics dataframe
2023-03-02 20:40:34,421:INFO:Finalizing model
2023-03-02 20:40:34,498:INFO:Uploading results into container
2023-03-02 20:40:34,499:INFO:Uploading model into container now
2023-03-02 20:40:34,499:INFO:_master_model_container: 31
2023-03-02 20:40:34,499:INFO:_display_container: 13
2023-03-02 20:40:34,500:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:34,500:INFO:create_model() successfully completed......................................
2023-03-02 20:40:34,574:INFO:SubProcess create_model() end ==================================
2023-03-02 20:40:34,574:INFO:choose_better activated
2023-03-02 20:40:34,577:INFO:SubProcess create_model() called ==================================
2023-03-02 20:40:34,578:INFO:Initializing create_model()
2023-03-02 20:40:34,578:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:40:34,578:INFO:Checking exceptions
2023-03-02 20:40:34,579:INFO:Importing libraries
2023-03-02 20:40:34,580:INFO:Copying training dataset
2023-03-02 20:40:34,583:INFO:Defining folds
2023-03-02 20:40:34,583:INFO:Declaring metric variables
2023-03-02 20:40:34,583:INFO:Importing untrained model
2023-03-02 20:40:34,583:INFO:Declaring custom model
2023-03-02 20:40:34,584:INFO:Gradient Boosting Classifier Imported successfully
2023-03-02 20:40:34,584:INFO:Starting cross validation
2023-03-02 20:40:34,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:40:34,983:INFO:Calculating mean and std
2023-03-02 20:40:34,983:INFO:Creating metrics dataframe
2023-03-02 20:40:34,986:INFO:Finalizing model
2023-03-02 20:40:35,089:INFO:Uploading results into container
2023-03-02 20:40:35,090:INFO:Uploading model into container now
2023-03-02 20:40:35,090:INFO:_master_model_container: 32
2023-03-02 20:40:35,090:INFO:_display_container: 14
2023-03-02 20:40:35,091:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:35,091:INFO:create_model() successfully completed......................................
2023-03-02 20:40:35,164:INFO:SubProcess create_model() end ==================================
2023-03-02 20:40:35,164:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=412, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8558
2023-03-02 20:40:35,165:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8567
2023-03-02 20:40:35,165:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-03-02 20:40:35,165:INFO:choose_better completed
2023-03-02 20:40:35,173:INFO:_master_model_container: 32
2023-03-02 20:40:35,173:INFO:_display_container: 13
2023-03-02 20:40:35,174:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-03-02 20:40:35,174:INFO:tune_model() successfully completed......................................
2023-03-02 20:41:17,776:INFO:Initializing plot_model()
2023-03-02 20:41:17,777:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:41:17,777:INFO:Checking exceptions
2023-03-02 20:41:17,784:INFO:Preloading libraries
2023-03-02 20:41:17,805:INFO:Copying training dataset
2023-03-02 20:41:17,806:INFO:Plot type: learning
2023-03-02 20:41:17,972:INFO:Fitting Model
2023-03-02 20:41:20,196:INFO:Visual Rendered Successfully
2023-03-02 20:41:20,275:INFO:plot_model() successfully completed......................................
2023-03-02 20:41:31,804:INFO:Initializing plot_model()
2023-03-02 20:41:31,804:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:41:31,805:INFO:Checking exceptions
2023-03-02 20:41:31,812:INFO:Preloading libraries
2023-03-02 20:41:31,837:INFO:Copying training dataset
2023-03-02 20:41:31,838:INFO:Plot type: auc
2023-03-02 20:41:32,002:INFO:Fitting Model
2023-03-02 20:41:32,002:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:41:32,003:INFO:Scoring test/hold-out set
2023-03-02 20:41:32,172:INFO:Visual Rendered Successfully
2023-03-02 20:41:32,245:INFO:plot_model() successfully completed......................................
2023-03-02 20:41:52,859:INFO:Initializing create_model()
2023-03-02 20:41:52,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:41:52,860:INFO:Checking exceptions
2023-03-02 20:41:52,882:INFO:Importing libraries
2023-03-02 20:41:52,883:INFO:Copying training dataset
2023-03-02 20:41:52,893:INFO:Defining folds
2023-03-02 20:41:52,893:INFO:Declaring metric variables
2023-03-02 20:41:52,897:INFO:Importing untrained model
2023-03-02 20:41:52,904:INFO:Logistic Regression Imported successfully
2023-03-02 20:41:52,913:INFO:Starting cross validation
2023-03-02 20:41:52,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:41:53,318:INFO:Calculating mean and std
2023-03-02 20:41:53,319:INFO:Creating metrics dataframe
2023-03-02 20:41:53,326:INFO:Finalizing model
2023-03-02 20:41:53,548:INFO:Uploading results into container
2023-03-02 20:41:53,548:INFO:Uploading model into container now
2023-03-02 20:41:53,556:INFO:_master_model_container: 33
2023-03-02 20:41:53,557:INFO:_display_container: 14
2023-03-02 20:41:53,557:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:41:53,557:INFO:create_model() successfully completed......................................
2023-03-02 20:42:04,485:INFO:Initializing create_model()
2023-03-02 20:42:04,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:42:04,486:INFO:Checking exceptions
2023-03-02 20:42:04,500:INFO:Importing libraries
2023-03-02 20:42:04,500:INFO:Copying training dataset
2023-03-02 20:42:04,504:INFO:Defining folds
2023-03-02 20:42:04,504:INFO:Declaring metric variables
2023-03-02 20:42:04,507:INFO:Importing untrained model
2023-03-02 20:42:04,510:INFO:Logistic Regression Imported successfully
2023-03-02 20:42:04,516:INFO:Starting cross validation
2023-03-02 20:42:04,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:42:04,877:INFO:Calculating mean and std
2023-03-02 20:42:04,878:INFO:Creating metrics dataframe
2023-03-02 20:42:04,882:INFO:Finalizing model
2023-03-02 20:42:04,973:INFO:Uploading results into container
2023-03-02 20:42:04,974:INFO:Uploading model into container now
2023-03-02 20:42:04,982:INFO:_master_model_container: 34
2023-03-02 20:42:04,982:INFO:_display_container: 15
2023-03-02 20:42:04,983:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:42:04,983:INFO:create_model() successfully completed......................................
2023-03-02 20:42:14,709:INFO:Initializing tune_model()
2023-03-02 20:42:14,709:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>)
2023-03-02 20:42:14,710:INFO:Checking exceptions
2023-03-02 20:42:14,737:INFO:Copying training dataset
2023-03-02 20:42:14,742:INFO:Checking base model
2023-03-02 20:42:14,742:INFO:Base model : Logistic Regression
2023-03-02 20:42:14,746:INFO:Declaring metric variables
2023-03-02 20:42:14,750:INFO:Defining Hyperparameters
2023-03-02 20:42:14,844:INFO:Tuning with n_jobs=-1
2023-03-02 20:42:14,844:INFO:Initializing RandomizedSearchCV
2023-03-02 20:42:15,258:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:15,274:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:15,293:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:15,653:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:16,035:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:17,388:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 6.087000000000001}
2023-03-02 20:42:17,389:INFO:Hyperparameter search completed
2023-03-02 20:42:17,389:INFO:SubProcess create_model() called ==================================
2023-03-02 20:42:17,390:INFO:Initializing create_model()
2023-03-02 20:42:17,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f222335b0d0>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 6.087000000000001})
2023-03-02 20:42:17,390:INFO:Checking exceptions
2023-03-02 20:42:17,390:INFO:Importing libraries
2023-03-02 20:42:17,390:INFO:Copying training dataset
2023-03-02 20:42:17,397:INFO:Defining folds
2023-03-02 20:42:17,397:INFO:Declaring metric variables
2023-03-02 20:42:17,401:INFO:Importing untrained model
2023-03-02 20:42:17,401:INFO:Declaring custom model
2023-03-02 20:42:17,406:INFO:Logistic Regression Imported successfully
2023-03-02 20:42:17,415:INFO:Starting cross validation
2023-03-02 20:42:17,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:42:17,792:INFO:Calculating mean and std
2023-03-02 20:42:17,794:INFO:Creating metrics dataframe
2023-03-02 20:42:17,800:INFO:Finalizing model
2023-03-02 20:42:17,937:INFO:Uploading results into container
2023-03-02 20:42:17,938:INFO:Uploading model into container now
2023-03-02 20:42:17,939:INFO:_master_model_container: 35
2023-03-02 20:42:17,939:INFO:_display_container: 16
2023-03-02 20:42:17,939:INFO:LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:42:17,939:INFO:create_model() successfully completed......................................
2023-03-02 20:42:18,025:INFO:SubProcess create_model() end ==================================
2023-03-02 20:42:18,025:INFO:choose_better activated
2023-03-02 20:42:18,028:INFO:SubProcess create_model() called ==================================
2023-03-02 20:42:18,029:INFO:Initializing create_model()
2023-03-02 20:42:18,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-02 20:42:18,029:INFO:Checking exceptions
2023-03-02 20:42:18,030:INFO:Importing libraries
2023-03-02 20:42:18,030:INFO:Copying training dataset
2023-03-02 20:42:18,034:INFO:Defining folds
2023-03-02 20:42:18,034:INFO:Declaring metric variables
2023-03-02 20:42:18,034:INFO:Importing untrained model
2023-03-02 20:42:18,034:INFO:Declaring custom model
2023-03-02 20:42:18,035:INFO:Logistic Regression Imported successfully
2023-03-02 20:42:18,035:INFO:Starting cross validation
2023-03-02 20:42:18,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-02 20:42:18,354:INFO:Calculating mean and std
2023-03-02 20:42:18,354:INFO:Creating metrics dataframe
2023-03-02 20:42:18,356:INFO:Finalizing model
2023-03-02 20:42:18,424:INFO:Uploading results into container
2023-03-02 20:42:18,425:INFO:Uploading model into container now
2023-03-02 20:42:18,425:INFO:_master_model_container: 36
2023-03-02 20:42:18,425:INFO:_display_container: 17
2023-03-02 20:42:18,425:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:42:18,425:INFO:create_model() successfully completed......................................
2023-03-02 20:42:18,499:INFO:SubProcess create_model() end ==================================
2023-03-02 20:42:18,500:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8409
2023-03-02 20:42:18,500:INFO:LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8431
2023-03-02 20:42:18,500:INFO:LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-03-02 20:42:18,500:INFO:choose_better completed
2023-03-02 20:42:18,508:INFO:_master_model_container: 36
2023-03-02 20:42:18,508:INFO:_display_container: 16
2023-03-02 20:42:18,509:INFO:LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-03-02 20:42:18,509:INFO:tune_model() successfully completed......................................
2023-03-02 20:42:27,320:INFO:Initializing plot_model()
2023-03-02 20:42:27,321:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=3,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.2, min_samples_leaf=1,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=412, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:42:27,321:INFO:Checking exceptions
2023-03-02 20:42:27,327:INFO:Preloading libraries
2023-03-02 20:42:27,360:INFO:Copying training dataset
2023-03-02 20:42:27,360:INFO:Plot type: learning
2023-03-02 20:42:27,528:INFO:Fitting Model
2023-03-02 20:42:29,709:INFO:Visual Rendered Successfully
2023-03-02 20:42:29,788:INFO:plot_model() successfully completed......................................
2023-03-02 20:42:32,322:INFO:Initializing plot_model()
2023-03-02 20:42:32,322:INFO:plot_model(plot=learning, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:42:32,323:INFO:Checking exceptions
2023-03-02 20:42:32,326:INFO:Preloading libraries
2023-03-02 20:42:32,327:INFO:Copying training dataset
2023-03-02 20:42:32,327:INFO:Plot type: learning
2023-03-02 20:42:32,494:INFO:Fitting Model
2023-03-02 20:42:32,620:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:33,570:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:34,339:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:34,620:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:37,718:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:38,441:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:39,170:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:39,944:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-03-02 20:42:40,458:INFO:Visual Rendered Successfully
2023-03-02 20:42:40,546:INFO:plot_model() successfully completed......................................
2023-03-02 20:43:00,243:INFO:Initializing plot_model()
2023-03-02 20:43:00,244:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=6.087000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=412, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:43:00,244:INFO:Checking exceptions
2023-03-02 20:43:00,250:INFO:Preloading libraries
2023-03-02 20:43:00,250:INFO:Copying training dataset
2023-03-02 20:43:00,250:INFO:Plot type: auc
2023-03-02 20:43:00,417:INFO:Fitting Model
2023-03-02 20:43:00,417:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-03-02 20:43:00,417:INFO:Scoring test/hold-out set
2023-03-02 20:43:00,574:INFO:Visual Rendered Successfully
2023-03-02 20:43:00,650:INFO:plot_model() successfully completed......................................
2023-03-02 20:47:44,894:INFO:Initializing plot_model()
2023-03-02 20:47:44,894:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:47:44,895:INFO:Checking exceptions
2023-03-02 20:47:44,920:INFO:Preloading libraries
2023-03-02 20:47:44,947:INFO:Copying training dataset
2023-03-02 20:47:44,947:INFO:Plot type: auc
2023-03-02 20:47:45,129:INFO:Fitting Model
2023-03-02 20:47:45,129:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:47:45,129:INFO:Scoring test/hold-out set
2023-03-02 20:47:45,359:INFO:Visual Rendered Successfully
2023-03-02 20:47:45,435:INFO:plot_model() successfully completed......................................
2023-03-02 20:49:13,887:INFO:Initializing plot_model()
2023-03-02 20:49:13,887:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:49:13,887:INFO:Checking exceptions
2023-03-02 20:49:13,908:INFO:Preloading libraries
2023-03-02 20:49:13,922:INFO:Copying training dataset
2023-03-02 20:49:13,922:INFO:Plot type: feature
2023-03-02 20:49:13,923:WARNING:No coef_ found. Trying feature_importances_
2023-03-02 20:49:14,122:INFO:Visual Rendered Successfully
2023-03-02 20:49:14,197:INFO:plot_model() successfully completed......................................
2023-03-02 20:50:22,682:INFO:Initializing plot_model()
2023-03-02 20:50:22,682:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:50:22,682:INFO:Checking exceptions
2023-03-02 20:50:22,711:INFO:Preloading libraries
2023-03-02 20:50:22,742:INFO:Copying training dataset
2023-03-02 20:50:22,742:INFO:Plot type: error
2023-03-02 20:50:22,898:INFO:Fitting Model
2023-03-02 20:50:22,898:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:50:22,898:INFO:Scoring test/hold-out set
2023-03-02 20:50:23,146:INFO:Visual Rendered Successfully
2023-03-02 20:50:23,222:INFO:plot_model() successfully completed......................................
2023-03-02 20:50:41,716:INFO:Initializing plot_model()
2023-03-02 20:50:41,716:INFO:plot_model(plot=prediction, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:50:41,716:INFO:Checking exceptions
2023-03-02 20:51:48,654:INFO:Initializing plot_model()
2023-03-02 20:51:48,654:INFO:plot_model(plot=pr, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:51:48,655:INFO:Checking exceptions
2023-03-02 20:51:48,680:INFO:Preloading libraries
2023-03-02 20:51:48,703:INFO:Copying training dataset
2023-03-02 20:51:48,703:INFO:Plot type: pr
2023-03-02 20:51:48,868:INFO:Fitting Model
2023-03-02 20:51:48,868:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:51:48,869:INFO:Scoring test/hold-out set
2023-03-02 20:51:49,085:INFO:Visual Rendered Successfully
2023-03-02 20:51:49,171:INFO:plot_model() successfully completed......................................
2023-03-02 20:52:30,764:INFO:Initializing plot_model()
2023-03-02 20:52:30,764:INFO:plot_model(plot=error, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:52:30,764:INFO:Checking exceptions
2023-03-02 20:52:30,789:INFO:Preloading libraries
2023-03-02 20:52:30,808:INFO:Copying training dataset
2023-03-02 20:52:30,808:INFO:Plot type: error
2023-03-02 20:52:30,965:INFO:Fitting Model
2023-03-02 20:52:30,965:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:52:30,965:INFO:Scoring test/hold-out set
2023-03-02 20:52:31,208:INFO:Visual Rendered Successfully
2023-03-02 20:52:31,297:INFO:plot_model() successfully completed......................................
2023-03-02 20:54:12,781:INFO:Initializing plot_model()
2023-03-02 20:54:12,781:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, system=True)
2023-03-02 20:54:12,781:INFO:Checking exceptions
2023-03-02 20:54:12,806:INFO:Preloading libraries
2023-03-02 20:54:12,831:INFO:Copying training dataset
2023-03-02 20:54:12,832:INFO:Plot type: auc
2023-03-02 20:54:12,995:INFO:Fitting Model
2023-03-02 20:54:12,995:WARNING:/home/jakowlew/.local/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-03-02 20:54:12,995:INFO:Scoring test/hold-out set
2023-03-02 20:54:13,234:INFO:Visual Rendered Successfully
2023-03-02 20:54:13,327:INFO:plot_model() successfully completed......................................
2023-03-02 20:55:20,322:INFO:Initializing predict_model()
2023-03-02 20:55:20,322:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7f2279055870>)
2023-03-02 20:55:20,322:INFO:Checking exceptions
2023-03-02 20:55:20,322:INFO:Preloading libraries
2023-03-02 20:55:20,325:INFO:Set up data.
2023-03-02 20:55:20,334:INFO:Set up index.
2023-03-02 21:04:19,954:INFO:Initializing finalize_model()
2023-03-02 21:04:19,954:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-03-02 21:04:19,955:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 21:04:19,959:INFO:Initializing create_model()
2023-03-02 21:04:19,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-03-02 21:04:19,959:INFO:Checking exceptions
2023-03-02 21:04:19,961:INFO:Importing libraries
2023-03-02 21:04:19,962:INFO:Copying training dataset
2023-03-02 21:04:19,962:INFO:Defining folds
2023-03-02 21:04:19,962:INFO:Declaring metric variables
2023-03-02 21:04:19,962:INFO:Importing untrained model
2023-03-02 21:04:19,962:INFO:Declaring custom model
2023-03-02 21:04:19,963:INFO:Random Forest Classifier Imported successfully
2023-03-02 21:04:19,965:INFO:Cross validation set to False
2023-03-02 21:04:19,965:INFO:Fitting Model
2023-03-02 21:04:20,720:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:20,720:INFO:create_model() successfully completed......................................
2023-03-02 21:04:20,806:INFO:_master_model_container: 36
2023-03-02 21:04:20,806:INFO:_display_container: 16
2023-03-02 21:04:20,822:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:20,822:INFO:finalize_model() successfully completed......................................
2023-03-02 21:04:27,014:INFO:Initializing finalize_model()
2023-03-02 21:04:27,015:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-03-02 21:04:27,016:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 21:04:27,020:INFO:Initializing create_model()
2023-03-02 21:04:27,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-03-02 21:04:27,020:INFO:Checking exceptions
2023-03-02 21:04:27,022:INFO:Importing libraries
2023-03-02 21:04:27,022:INFO:Copying training dataset
2023-03-02 21:04:27,023:INFO:Defining folds
2023-03-02 21:04:27,023:INFO:Declaring metric variables
2023-03-02 21:04:27,023:INFO:Importing untrained model
2023-03-02 21:04:27,023:INFO:Declaring custom model
2023-03-02 21:04:27,024:INFO:Random Forest Classifier Imported successfully
2023-03-02 21:04:27,025:INFO:Cross validation set to False
2023-03-02 21:04:27,025:INFO:Fitting Model
2023-03-02 21:04:27,172:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:27,172:INFO:create_model() successfully completed......................................
2023-03-02 21:04:27,257:INFO:_master_model_container: 36
2023-03-02 21:04:27,257:INFO:_display_container: 16
2023-03-02 21:04:27,273:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:27,273:INFO:finalize_model() successfully completed......................................
2023-03-02 21:04:34,099:INFO:Initializing finalize_model()
2023-03-02 21:04:34,100:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-03-02 21:04:34,100:INFO:Finalizing RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False)
2023-03-02 21:04:34,105:INFO:Initializing create_model()
2023-03-02 21:04:34,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f2222feb670>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=2,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       n_estimators=220, n_jobs=-1, oob_score=False,
                       random_state=412, verbose=0, warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-03-02 21:04:34,106:INFO:Checking exceptions
2023-03-02 21:04:34,108:INFO:Importing libraries
2023-03-02 21:04:34,108:INFO:Copying training dataset
2023-03-02 21:04:34,109:INFO:Defining folds
2023-03-02 21:04:34,109:INFO:Declaring metric variables
2023-03-02 21:04:34,109:INFO:Importing untrained model
2023-03-02 21:04:34,109:INFO:Declaring custom model
2023-03-02 21:04:34,110:INFO:Random Forest Classifier Imported successfully
2023-03-02 21:04:34,111:INFO:Cross validation set to False
2023-03-02 21:04:34,111:INFO:Fitting Model
2023-03-02 21:04:34,276:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:34,276:INFO:create_model() successfully completed......................................
2023-03-02 21:04:34,363:INFO:_master_model_container: 36
2023-03-02 21:04:34,363:INFO:_display_container: 16
2023-03-02 21:04:34,379:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer'...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight='balanced',
                                        criterion='entropy', max_depth=11,
                                        max_features='log2',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.005,
                                        min_samples_leaf=2, min_samples_split=5,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=220, n_jobs=-1,
                                        oob_score=False, random_state=412,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-03-02 21:04:34,379:INFO:finalize_model() successfully completed......................................
